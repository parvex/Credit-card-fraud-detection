---
title: "Credit Card Fraud Detection - Zaawansowane uczenie maszynowe"
author: "Gabriel Rębacz, Michał Belniak"
date: "12/12/2020"
output:
  html_document:
    df_print: paged
    code_folding: hide
---

# Interpretacja tematu projektu

Wybranym zadaniem jest analiza problemu klasyfikacji na zbiorze danych _Credit Card Fraud Detection_ dostępnym w serwisie Kaggle.com.

Zakres projektu obejmuje 4 podstawowe sfery:

* wnikliwą analizę zbioru danych,
* przetworzenie zbioru danych do postaci odpowiednich dla poszczególnych modeli,
* przygotowanie, uczenie i strojenie modeli wybranych spośród dostępnych w języku R,
* ocenę i porównanie modeli wraz z adekwatnymi wnioskami.

# Analiza danych

```{r init}
Sys.setlocale(category = "LC_ALL", locale = "Polish")
library(pacman)
pacman::p_load(skimr, 
               dplyr, 
               ggplot2, 
               scales, 
               corrplot, 
               tidymodels, 
               tune, 
               workflows, 
               tictoc, 
               themis, 
               reshape2, 
               glmnet, 
               tensorflow, 
               keras)
def_par = par(no.readonly = TRUE)
#data loading
data_df <- read.csv("creditcard.csv")

data_df$Class <- as.factor(data_df$Class) 
n_columns <- ncol(data_df)
# data_df$ClassNumeric <- as.numeric(data_df$Class) - 1
```


Zbiór danych należy przeanalizować pod kątem czynników które mają lub mogą mieć wpływ na sposób ich przygotowania oraz dobór parametrów modeli.


Pierwsze 6 rekordków zbioru danych:
```{r head}
head(data_df)
```


```{r nulls-check}
nans <- sum(is.na(data_df))

if (nans > 0) {
  sprintf("Zbiór danych ma %d wartości NaN", nans)
  # TODO eliminate NaNs in this case
} else {
  print("Zbiór nie ma wartości NaN")
}

```

Podstawowa analiza statystyczna zbioru danych:

```{r summarize}
summarize(data_df)
```


```{r rozklad-klas}
ggplot(data_df, aes(x = Class)) +
  geom_bar(aes(y = (..count..) / sum(..count..))) +
  scale_y_continuous(labels = percent) +
  labs(y = "%", x = "Klasa") +
  ggtitle("Procentowy rozkład klas")
```
```{r rozklad-klas-tabela}
summarize(data_df, type = "factor", variables = "Class", cumulative = TRUE, digits = 4)
```

Jak widać z danych odnośnie kolumny class - zbiór danych jest niezrównoważony.

```{r histogram-wartosci-transakcji}
hist(data_df$Amount,
  breaks = 500,
  xlim = c(0, max(data_df$Amount)),
  xlab = "Amount",
  ylab = "Frequency",
  main = "Hostogram wartości transakcji"
)
```

```{r wartosc-transakcji-boxlpot}
boxplot(data_df$Amount,
        main="Wykres pudełkowy wartości transakcji",
        ylab="Wartość transakcji"
)
```

Wartości transakcji są skupione w większości na najniższych wartościach mimo że występują również ekstremalne wartości.

```{r correlation-matrix-unbalanced}
#correlation matrix for unbalanced set
data_df$Class <- as.numeric(data_df$Class) - 1
cor_matrix <- cor(data_df)
corrplot(cor_matrix,
         type = "lower",
         tl.col = "black", tl.srt = 45,
         main = "Macierz korelacji dla niezbalansowanego zbioru",
         mar=c(0,0,1,0)
)
data_df$Class <- as.factor(data_df$Class)
```

Jak widać z macierzy korelacji dla niezbalansowanego zbioru nie wynika wiele. Przyczyną tego są zaburzenia wynikające właśnie z jego niezbalansowania. Należy sprawdzić czy zbalansowanie poprawi odczyt korelacji.

## Przetwarzanie danych

W celu dalszej analizy zbioru zastosowane zostaną przekształcenia:

* kolumny Time i Amount zostaną poddane skalowaniu,
* zbiór zostanie podzielony na dwa zbalansowane zbiory:
  + z wykorzystaniem techniki undersampling;
  + z wykorzystaniem techniki oversampling.

Undersampling losowo dobiera wartości z klasą dominującą. Oversampling zaś generuje nowe wartości klasy o mniejszej ilości wartości na podstawie istniejących wartości.

```{r scale}
data_df <- data_df %>% mutate_at(c("Amount", "Time"), ~ (scale(.) %>% as.vector()))
```

## Undersampling

Zbiór poddany zostanie undersamplingowi dzięki czemu powstanie zbalansowany zbiór złożony z istniejących wartości klasy stanowiącej mniejszość oraz losowo wybranych wartościach o klasie większościowej.
```{r undersampling-cor-matrix}
# Perform undersampling and plot correlation matrix

undersample_recipe <- recipe(Class~., data = data_df) %>%
  themis::step_downsample(Class) %>%
  prep()

undersampled_df <- bake(undersample_recipe, new_data=NULL)
undersampled_df$Class <- as.numeric(undersampled_df$Class) - 1

table(undersampled_df$Class)

skim(undersampled_df)

cor_matrix <- cor(undersampled_df)
corrplot(cor_matrix,
  type = "lower",
  tl.col = "black", tl.srt = 45,
  main = "Correlation matrix for undersampled set",
  mar = c(0,0,1,0)
)
```

Z macierzy korelacji można lepiej wywnioskować korelacje między klasą a pozostałymi kolumnami.


Poniżej przedstawione są wykresy pudełkowe dla atrybutów o największych korelacjach w zbiorze poddanym undersamplingowi.

```{r undersampling-cor-boxplot}
# Take variables which have significant correlation with Class. Use oversampled set.

class_corrs <- cor_matrix["Class", ][-n_columns]
big_positive_corrs <- names(class_corrs)[class_corrs > 0.5]
big_negative_corrs <- names(class_corrs)[class_corrs < -0.5]

big_corrs <- c(big_negative_corrs, big_positive_corrs)
undersampled_df$Class <- as.factor(undersampled_df$Class)
melted <- undersampled_df %>% select(big_corrs, Class) %>% melt(id.var = "Class")
ggplot(melted, aes(x=variable, y=value)) + 
  geom_boxplot(aes(fill=Class)) + 
  facet_wrap( ~ variable, scales="free")
```

## Oversampling 

Zbiór poddany zostanie oversampingowi dzięki czemu powstanie zbalansowany zbiór złożony z istniejących wartości klasy mniejszościowej, nowo wygenerowanych wartości klasy mniejszościowej oraz losowo wybranych wartościach o klasie większościowej.

```{r oversampling-cor-matrix}
# Perform oversampling and plot correlation matrix

oversample_recipe <- recipe(Class~., data = data_df) %>%
  themis::step_smote(Class) %>%
  prep()

oversampled_df <- bake(oversample_recipe, new_data=NULL)

table(oversampled_df$Class)

skim(oversampled_df)

oversampled_df$Class <- as.numeric(oversampled_df$Class) - 1
cor_matrix <- cor(oversampled_df)
corrplot(cor_matrix,
  type = "lower",
  tl.col = "black", tl.srt = 45,
  main = "Correlation matrix for oversampled set",
  mar=c(0,0,1,0)
  
)
```

Poniżej przedstawione są wykresy pudełkowe dla atrybutów o największych korelacjach w zbiorze poddanym oversamplingowi.

```{r oversampling-cor-boxplot}
# Take variables which have significant correlation with Class. Use oversampled set.

class_corrs <- cor_matrix["Class", ][-n_columns]
big_positive_corrs <- names(class_corrs)[class_corrs > 0.5]
big_negative_corrs <- names(class_corrs)[class_corrs < -0.5]
big_corrs <- c(big_negative_corrs, big_positive_corrs)

oversampled_df$Class <- as.factor(oversampled_df$Class)
melted <- oversampled_df %>% select(big_corrs, Class) %>% melt(id.var = "Class")
ggplot(melted, aes(x=variable, y=value)) + 
  geom_boxplot(aes(fill=Class)) + 
  facet_wrap( ~ variable, scales="free")
```

# Przygotowanie, uczenie i strojenie wybranych modeli

W rozdziale tym przeprowadzone zostanie definiowanie modeli, uczenie oraz ich strojenie. Do tworzenia modeli wykorzystano bibliotekę tidymodels. Zbiór danych zostanie podzielony na dwa zbiory: trenujący oraz testujący. Strojenie parametrów odbędzie się na zbiorze trenującym z wykorzystaniem na nim 10-krotnej walidacji krzyżowej. Modele o najlepszych parametrach zostaną ostatecznie wyuczone na całym zbiorze trenującym i ocenione na zbiorze trenującym. 

Głównym kryterium oceny będzie pole pod krzywą ROC. Do tworzenia modeli, uczenua oraz ich strojenia wykorzystana zostanie biblioteka tidymodels.

```{r}

data_split <- initial_split(data_df, strata = Class)
data_train <- training(cell_split)
data_test  <- testing(cell_split)
folds <- vfold_cv(data_train, strata = Class)

log_reg_tune_spec <-
  logistic_reg(
    penalty = tune(),
    mixture = tune()
  ) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

tree_tune_spec <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
    min_n = tune()
  ) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")

neural_network_spec <-
  mlp(epochs = 20, 
      hidden_units = tune(), 
      dropout = tune() ) %>%
  set_mode("classification") %>% 
  # Also set engine-specific `verbose` argument to prevent logging the results: 
  set_engine("keras", verbose = 0)


tune_models <- list(log_reg_tune_spec, tree_tune_spec, neural_network_spec)
recipes <- list(undersample_recipe, oversample_recipe)

workflows <- list()

i <- 1
for (recipe in recipes) {
  for (model in tune_models) {
      workflows[[i]] <- workflow() %>%
               add_model(model) %>%
               add_recipe(recipe)
      
      i <- i + 1
  }
}


results <- list()
i <- 1

tic()
for (workflow in workflows) {
HP_set <- parameters(workflow)

results[[i]] <-
  workflow %>% 
  tune_bayes(
    resamples = folds,
    # To use non-default parameter ranges
    param_info = HP_set,
    # Generate five at semi-random to start
    initial = 5,
    iter = 10,
    # How to measure performance?
    metrics = metric_set(roc_auc),
    control = control_bayes(no_improve = 30, verbose = TRUE)
  )
  i <- i+1
    
}
toc()

# cos jest nie tak bo chyba za dlugo sie przeszukuje, moze undersampling nie dziala na faldach

Znalezione najlepsze hiperparametry dla drzewa przedstawione są poniżej.

tree_res %>% 
  collect_metrics()
```


## Drzewo klasyfikacji

## Regresja liniowa

## Sieć neuronowa

# Ocena jakości modeli

## Drzewo klasyfikacji

## Regresja liniowa

## Sieć neuronowa

# Podsumowanie

---
title: "Credit Card Fraud Detection - Zaawansowane uczenie maszynowe"
author: "Gabriel Rębacz, Michał Belniak"
date: "12/12/2020"
output:
  html_document:
    df_print: paged
    code_folding: hide
---

# Interpretacja tematu projektu

Wybranym zadaniem jest analiza problemu klasyfikacji na zbiorze danych _Credit Card Fraud Detection_ dostępnym w serwisie Kaggle.com.

Zakres projektu obejmuje 4 podstawowe sfery:

* wnikliwą analizę zbioru danych,
* przetworzenie zbioru danych do postaci odpowiednich dla poszczególnych modeli,
* przygotowanie, uczenie i strojenie modeli wybranych spośród dostępnych w języku R,
* ocenę i porównanie modeli wraz z adekwatnymi wnioskami.

# Analiza danych

```{r init}
Sys.setlocale(category = "LC_ALL", locale = "Polish")
install.packages("pacman")
library(pacman)
pacman::p_load(skimr, 
               dplyr, 
               ggplot2, 
               scales, 
               corrplot, 
               tidymodels, 
               tune, 
               workflows, 
               tictoc, 
               themis, 
               reshape2, 
               glmnet, 
               tensorflow, 
               keras,
               mlbench,
               caret,
               e1071,
               randomForest,
               ranger)
def_par = par(no.readonly = TRUE)
#data loading
if (!grepl('src$', getwd())) {
  setwd("src")
}
source("data-analysis.r")
data_df <- read.csv("creditcard.csv")
data_df$Class <- as.factor(data_df$Class)
```


Zbiór danych należy przeanalizować pod kątem czynników które mają lub mogą mieć wpływ na sposób ich przygotowania oraz dobór parametrów modeli.


Pierwsze 6 rekordków zbioru danych:
```{r head}
head(data_df)
```


```{r nulls-check}
checkNans(data_df)

```

Podstawowa analiza statystyczna zbioru danych:

```{r summarize}
skim(data_df)
```


```{r rozklad-klas}
ggplot(data_df, aes(x = Class)) +
  geom_bar(aes(y = (..count..) / sum(..count..))) +
  scale_y_continuous(labels = percent) +
  labs(y = "%", x = "Klasa") +
  ggtitle("Procentowy rozkład klas")
```
```{r rozklad-klas-tabela}
summarize(data_df, type = "factor", variables = "Class", cumulative = TRUE, digits = 4)
```

Jak widać z danych odnośnie kolumny class - zbiór danych jest niezrównoważony.

Skalowanie kolumn Time oraz Amount.

```{r scale}
data_df <- data_df %>% mutate_at(c("Amount", "Time"), ~ (scale(.) %>% as.vector()))
```

Wartości transakcji są skupione w większości na najniższych wartościach mimo że występują również ekstremalne wartości.

```{r correlation-matrix-unbalanced}
#correlation matrix for unbalanced set
cor_matrix <- corMatrix(data_df, "Macierz korelacji dla niezbalansowanego zbioru")
cor_matrix
```

Jak widać z macierzy korelacji dla niezbalansowanego zbioru nie wynika wiele. Przyczyną tego są zaburzenia wynikające właśnie z jego niezbalansowania. Należy sprawdzić czy zbalansowanie poprawi odczyt korelacji.

## Przetwarzanie danych

W celu dalszej analizy zbioru zastosowane zostaną przekształcenia:

* zbiór zostanie podzielony na dwa zbalansowane zbiory:
  + z wykorzystaniem techniki undersampling;
  + z wykorzystaniem techniki oversampling.

Undersampling losowo dobiera wartości z klasą dominującą. Oversampling zaś generuje nowe wartości klasy o mniejszej ilości wartości na podstawie istniejących wartości.

## Undersampling

Zbiór poddany zostanie undersamplingowi dzięki czemu powstanie zbalansowany zbiór złożony z istniejących wartości klasy stanowiącej mniejszość oraz losowo wybranych wartościach o klasie większościowej.
```{r undersampling-cor-matrix}
# Perform undersampling and plot correlation matrix

undersample_recipe <- recipe(Class~., data = data_df) %>%
  themis::step_downsample(Class) %>%
  prep()

undersampled_df <- bake(undersample_recipe, new_data=NULL)

table(undersampled_df$Class)

cor_matrix <- corMatrix(undersampled_df, "Macierz korelacji dla zbioru poddanemu \"undersampling\".")
```

Z macierzy korelacji dla danych zbalansowanych wynikaja korelacje między klasą a pozostałymi kolumnami.


Poniżej przedstawione są wykresy pudełkowe dla atrybutów o największych korelacjach w zbiorze poddanym undersamplingowi.

```{r undersampling-cor-boxplot}
# Take variables which have significant correlation with Class. Use oversampled set.
bigCorrsBoxPlot(undersampled_df, cor_matrix)
```

## Oversampling 

Zbiór poddany zostanie oversampingowi dzięki czemu powstanie zbalansowany zbiór złożony z istniejących wartości klasy mniejszościowej, nowo wygenerowanych wartości klasy mniejszościowej oraz losowo wybranych wartościach o klasie większościowej.

```{r oversampling-cor-matrix}
# Perform oversampling and plot correlation matrix

oversample_recipe <- recipe(Class~., data = data_df) %>%
  themis::step_smote(Class) %>%
  prep()

oversampled_df <- bake(oversample_recipe, new_data=NULL)

table(oversampled_df$Class)

skim(oversampled_df)

cor_matrix <- corMatrix(oversampled_df, "Macierz korelacji dla zbioru poddanemu \"oversampling\".")
```

Poniżej przedstawione są wykresy pudełkowe dla atrybutów o największych korelacjach w zbiorze poddanym oversamplingowi.

```{r oversampling-cor-boxplot}
# Take variables which have significant correlation with Class. Use oversampled set.
bigCorrsBoxPlot(oversampled_df, cor_matrix)
```

### Wybór atrybutów

W tym podrozdziale przeprowadzimy selekcję atrybutów za pomocą automatycznej metody wybierajacej 10 atrybutów o najwiekszej wartosci "variable importance" z lasu losowego. 

```{r feature selection}
# ensure the results are repeatable
set.seed(7)
trControl = trainControl(method="cv", number = 5, allowParallel = TRUE, verbose = TRUE)
rf_fit <- train(Class ~ ., data = data_df, method = "ranger", num.trees = 50, trControl = trControl, importance = 'impurity')
imp <- varImp(rf_fit)
plot(features_imp, top = 20)
imp <- data.frame(imp[1])
features <- rownames(imp)[order(imp$Overall, decreasing=TRUE)][1:10]
```
Wybrane atrybuty: ${features}

```{r feature selection continuation}
data_df_selected <- data_df[,which(names(data_df) %in% c(features, "Class"))]
data_df_selected$Class <- as.numeric(data_df_selected$Class) - 1
cor_matrix <- corMatrix(data_df_selected, "Macierz korelacji dla zbioru poddanemu selekcji atrybutów.")

```

# Przygotowanie, uczenie i strojenie wybranych modeli

W rozdziale tym przeprowadzone zostanie definiowanie modeli, uczenie oraz ich strojenie. Do tworzenia modeli wykorzystano bibliotekę tidymodels. Zbiór danych zostanie podzielony na dwa zbiory: trenujący oraz testujący. Strojenie parametrów odbędzie się na zbiorze trenującym z wykorzystaniem na nim 10-krotnej walidacji krzyżowej. Modele o najlepszych parametrach zostaną ostatecznie wyuczone na całym zbiorze trenującym i ocenione na zbiorze trenującym. 

Głównym kryterium oceny będzie pole pod krzywą ROC. Do tworzenia modeli, uczenua oraz ich strojenia wykorzystana zostanie biblioteka tidymodels.

```{r}

data_split <- initial_split(data_df, strata = Class)
data_train <- training(data_split)
data_test  <- testing(data_split)
folds <- vfold_cv(data_train, strata = Class)

log_reg_tune_spec <-
  logistic_reg(
    penalty = tune(),
    mixture = tune()
  ) %>%
  set_engine("glmnet") %>%
  set_mode("classification")

tree_tune_spec <- 
  decision_tree(
    cost_complexity = tune(),
    tree_depth = tune(),
    min_n = tune()
  ) %>% 
  set_engine("rpart") %>% 
  set_mode("classification")

neural_network_spec <-
  mlp(epochs = 20, 
      hidden_units = tune(), 
      dropout = tune() ) %>%
  set_mode("classification") %>% 
  # Also set engine-specific `verbose` argument to prevent logging the results: 
  set_engine("keras", verbose = 1)


tune_models <- list(log_reg_tune_spec, tree_tune_spec, neural_network_spec)
recipes <- list(undersample_recipe, oversample_recipe)

workflows <- list()

i <- 1
for (recipe in recipes) {
  for (model in tune_models) {
      workflows[[i]] <- workflow() %>%
               add_model(model) %>%
               add_recipe(recipe)
      
      i <- i + 1
  }
}


results <- list()
i <- 1

tic()
for (workflow in workflows) {
  HP_set <- parameters(workflow)

  results[[i]] <-
    workflow %>% 
  workflow %>% 
    workflow %>% 
    tune_bayes(
      resamples = folds,
      # To use non-default parameter ranges
      param_info = HP_set,
      # Generate five at semi-random to start
      initial = 5,
      iter = 10,
      # How to measure performance?
      metrics = metric_set(roc_auc),
      control = control_bayes(no_improve = 30, verbose = TRUE)
    )
    i <- i+1
    
}
toc()

# cos jest nie tak bo chyba za dlugo sie przeszukuje, moze undersampling nie dziala na faldach
```
Znalezione najlepsze hiperparametry dla drzewa przedstawione są poniżej.



## Drzewo klasyfikacji

## Regresja liniowa

## Sieć neuronowa

# Ocena jakości modeli

## Drzewo klasyfikacji

## Regresja liniowa

## Sieć neuronowa

# Podsumowanie

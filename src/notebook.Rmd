---
title: "Credit Card Fraud Detection - Zaawansowane uczenie maszynowe"
author: "Gabriel Rębacz, Michał Belniak"
date: "12/12/2020"
output:
  html_document:
    df_print: paged
    code_folding: hide
---

# Interpretacja tematu projektu

Wybranym zadaniem jest analiza problemu klasyfikacji na zbiorze danych _Credit Card Fraud Detection_ dostępnym w serwisie Kaggle.com.

Zakres projektu obejmuje 4 podstawowe sfery:

* wnikliwą analizę zbioru danych,
* przetworzenie zbioru danych do postaci odpowiednich dla poszczególnych modeli,
* przygotowanie, uczenie i strojenie modeli wybranych spośród dostępnych w języku R,
* ocenę i porównanie modeli wraz z adekwatnymi wnioskami.

# Analiza danych

```{r init}
Sys.setlocale(category = "LC_ALL", locale = "Polish")
install.packages("pacman")
library(pacman)
pacman::p_load(skimr, 
               dplyr, 
               ggplot2, 
               scales, 
               corrplot, 
               tidymodels, 
               tune, 
               workflows, 
               tictoc, 
               themis, 
               reshape2, 
               glmnet, 
               tensorflow, 
               keras,
               mlbench,
               caret,
               e1071,
               randomForest,
               ranger)
def_par = par(no.readonly = TRUE)
#data loading
if (!grepl('src$', getwd())) {
  setwd("src")
}
source("common.r")
load("rdata/datadf.Rdata")
```


Zbiór danych należy przeanalizować pod kątem czynników które mają lub mogą mieć wpływ na sposób ich przygotowania oraz dobór parametrów modeli.


Pierwsze 6 rekordków zbioru danych:
```{r head}
head(data_df)
```


```{r nulls-check}
checkNans(data_df)

```

Podstawowa analiza statystyczna zbioru danych:

```{r summarize}
skim(data_df)
```


```{r rozklad-klas}
common_theme <- theme(plot.title = element_text(hjust = 0.5, face = "bold"))

ggplot(data_df, aes(x = Class, y = prop.table(stat(count)), fill = factor(Class),
                          label = scales::percent(prop.table(stat(count))))) +
  geom_bar(aes(y = (..count..) / sum(..count..))) +
  labs(y = "%", x = "Klasa") +
  geom_text(stat = 'count',
              position = position_dodge(.9), 
              vjust = -0.5, 
              size = 3) +
  scale_x_discrete(labels = c("0", "1"))+
  scale_y_continuous(labels = scales::percent)+
  ggtitle("Procentowy rozkład klas") + 
  common_theme + 
  labs(fill = "Klasa")
```
```{r rozklad-klas-tabela}
summarize(data_df, type = "factor", variables = "Class", cumulative = TRUE, digits = 4)
```

Jak widać z danych odnośnie kolumny class - zbiór danych jest niezrównoważony.

Skalowanie kolumn Time oraz Amount.

```{r scale}
data_df <- data_df %>% mutate_at(c("Amount", "Time"), ~ (scale(.) %>% as.vector()))
```

Wartości transakcji są skupione w większości na najniższych wartościach, jednakże występują również ekstremalne wartości.

```{r correlation-matrix-unbalanced}
#correlation matrix for unbalanced set
cor_matrix <- corMatrix(data_df, "Macierz korelacji dla niezbalansowanego zbioru")
cor_matrix
```

Jak widać, z macierzy korelacji dla niezbalansowanego zbioru nie wynika wiele. Przyczyną tego są zaburzenia wynikające właśnie z jego niezbalansowania. Należy sprawdzić czy zbalansowanie poprawi odczyt korelacji.

## Przetwarzanie danych

W celu dalszej analizy zbioru zastosowano przekształcenia:

* zbiór został podzielony na dwa zbalansowane zbiory:
  + z wykorzystaniem techniki undersampling;
  + z wykorzystaniem techniki oversampling.

Undersampling losowo dobiera wartości z klasą dominującą. Oversampling zaś generuje nowe wartości klasy o mniejszej liczności na podstawie istniejących wartości.

## Undersampling

Zbiór poddany został przekształceniu undersampling dzięki czemu powstał zbalansowany zbiór złożony z istniejących wartości klasy stanowiącej mniejszość oraz losowo wybranych rekordów o klasie większościowej.
```{r undersampling-cor-matrix}
# Perform undersampling and plot correlation matrix

undersample_recipe <- recipe(Class~., data = data_df) %>%
  themis::step_downsample(Class)

undersampled_df <-undersample_recipe %>% prep(training = data_df) %>% bake(new_data=NULL)

table(undersampled_df$Class)

skim(undersampled_df)

cor_matrix <- corMatrix(undersampled_df, "Macierz korelacji dla zbioru poddanemu \"undersampling\".")
```

Z macierzy korelacji dla danych zbalansowanych wynikają korelacje między klasą a pozostałymi kolumnami.

Poniżej przedstawione są wykresy pudełkowe dla atrybutów o największych korelacjach w zbiorze poddanym przekształceniu undersampling.

```{r undersampling-cor-boxplot}
# Take variables which have significant correlation with Class. Use oversampled set.
class_corrs <- cor_matrix["Class", ][-ncol(undersampled_df)]
big_corrs <- names(class_corrs)[abs(class_corrs) > 0.5]

melted <- undersampled_df %>% select(big_corrs, Class) %>% melt(id.var = "Class")
ggplot(melted, aes(x=variable, y=value)) + 
  geom_boxplot(aes(fill=Class)) + 
  facet_wrap( ~ variable, scales="free")

undersampled_df$Class <- as.factor(undersampled_df$Class)
```

## Oversampling 

Zbiór poddany został przekształceniu oversamping, dzięki czemu powstał zbalansowany zbiór złożony z istniejących rekordów klasy mniejszościowej, nowo wygenerowanych rekordów klasy mniejszościowej oraz losowo wybranych rekordów o klasie większościowej.

```{r oversampling-cor-matrix}
# Perform oversampling and plot correlation matrix

oversample_recipe <- recipe(Class~., data = data_df) %>%
  themis::step_smote(Class)

oversampled_df <- oversample_recipe %>% prep(training = data_df) %>% bake(new_data=NULL)

table(oversampled_df$Class)

skim(oversampled_df)

cor_matrix <- corMatrix(oversampled_df, "Macierz korelacji dla zbioru poddanemu \"oversampling\".")
```

Poniżej przedstawione są wykresy pudełkowe dla atrybutów o największych korelacjach w zbiorze poddanym oversamplingowi.

```{r oversampling-cor-boxplot}
# Take variables which have significant correlation with Class. Use oversampled set.
class_corrs <- cor_matrix["Class", ][-ncol(oversampled_df)]
big_corrs <- names(class_corrs)[abs(class_corrs) > 0.5]

melted <- oversampled_df %>% select(big_corrs, Class) %>% melt(id.var = "Class")
ggplot(melted, aes(x=variable, y=value)) + 
  geom_boxplot(aes(fill=Class)) + 
  facet_wrap( ~ variable, scales="free")

oversampled_df$Class <- as.factor(oversampled_df$Class)
```

### Wybór atrybutów

W tym podrozdziale przeprowadzono selekcję atrybutów za pomocą automatycznej metody wybierajacej 10 atrybutów o najwiekszej wartosci "variable importance" z lasu losowego. 
Wykorzystano las losowy z pakietu "ranger" złożony z 50 drzew.
```{r feature selection}
load("rdata/rf_fit.Rdata")
imp <- varImp(rf_fit, scale = FALSE)
plot(imp)
imp <- data.frame(imp[1])
rownames(imp)[imp$Overall > mean(imp$Overall)]
features <- rownames(imp)[imp$Overall > mean(imp$Overall)]
```
Wybrane atrybuty: ${features}

Ponownie przeprowadzono przekształcenia undersampling oraz oversampling, tym razem na danych z wyłącznie wybranymi atrybutami.
```{r feature selection continuation - undersample dataset with selected attributes}
data_df_selected <- data_df[,which(names(data_df) %in% c(features, "Class"))]

selected_undersample_recipe <- recipe(Class~., data = data_df_selected) %>%
  themis::step_downsample(Class) %>%
  prep()

selected_undersampled_df <- bake(selected_undersample_recipe, new_data=NULL)

cor_matrix <- corMatrix(selected_undersampled_df, "Macierz korelacji dla zbioru poddanemu selekcji atrybutów oraz \"undersampling\".")
```

```{r feature selection continuation - undersample dataset with selected attributes}

selected_oversample_recipe <- recipe(Class~., data = data_df_selected) %>%
  themis::step_smote(Class) %>%
  prep()

selected_oversampled_df <- bake(selected_oversample_recipe, new_data=NULL)
cor_matrix <- corMatrix(selected_oversampled_df, "Macierz korelacji dla zbioru poddanemu selekcji atrybutów oraz \"oversampling\".")
```

Z macierzy korelacji wynikają silne korelacje między wybranymi atrybutami oraz pojęciem docelowym.

# Przygotowanie, uczenie i strojenie wybranych modeli

W rozdziale tym przeprowadzono definiowanie modeli, uczenie oraz ich strojenie. Zbiór danych podzielono na dwa zbiory: trenujący oraz testujący. 
Najpierw przeprowadzono eksperymenty z zastosowaniem techniki undersample, a pózniej techniki oversample. 
W ramach porównania eksperymenty zostały przeprowadzone na pełnym zbiorze oraz na zbiorze zawierajacym wylacznie 10 wybranych atrybutow.
Strojenie parametrów odbyło się na zbiorze trenującym z wykorzystaniem na nim 10-krotnej walidacji krzyżowej.
Modele o najlepszych parametrach zostały ostatecznie wyuczone na całym zbiorze trenującym i ocenione na zbiorze testującym. 

Głównym kryterium oceny jakości modeli jest pole pod krzywą ROC. Do tworzenia modeli, uczenia oraz ich strojenia wykorzystana została biblioteka tidymodels.

## Tutaj tylko wypisujemy wyniki, krzywe uczenia i inne takie rzeczy, ktore juz sa gotowe w plikach Rdata.

## Regresja logistyczna
```{r logistic regression}
load("rdata/log_req_undersample_final_fit.Rdata")
log_req_undersample_final_fit %>% collect_metrics()

load( "rdata/log_req_undersample_selected_final_fit.Rdata")
log_req_undersample_selected_final_fit %>% collect_metrics()

load("rdata/log_req_oversample_final_fit.Rdata")
log_req_oversample_final_fit %>% collect_metrics()

load("data/log_req_oversample_selected_final_fit.Rdata")
log_req_oversample_selected_final_fit %>% collect_metrics() # i różne takie trza porobc. Trza ogarnac jak wyluskiwac F-score, accuracy itp.
#
```

## Drzewo klasyfikacji  

```{r decision tree}
#TODO
```

## Sieć neuronowa

```{r neural network}
#TODO
```

  
# Podsumowanie
